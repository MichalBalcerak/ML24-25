{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8HiB4f4nvUe8Bny0es2uK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichalBalcerak/ML24-25/blob/main/Homework11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Theory Exploration**\n",
        "\n",
        "\n",
        "### What is a **transposed convolution**?\n",
        "A **transposed convolution** (or **\"deconvolution\"**) is a type of neural network layer. It is, in some way, an invertion of *convolution* neural layer beacuase it works by applying the convolution kernel to eaxch individual input value. This value is treated as a scalar multiplier:\n",
        "*   For each input value, the entire kernel is multiplied by that value.\n",
        "*   The resulting values are then added into the corresponding region of the output, according to the stride.\n",
        "This way, transposed convolution distributes the influence of each input value across multiple output positions, instead of collecting information from multiple inputs (neighboring pixels) as in regular convolution.\n",
        "\n",
        "\n",
        "### How does it differ from a regular convolution?\n",
        "**Regular convolution:**\n",
        "*   aggregates input into smaller output,\n",
        "*   detects patterns in the image by gathering local features,\n",
        "*   kernel is moved over the input,\n",
        "*   computed by discrete convolution.\n",
        "\n",
        "**Transposed convolution:**\n",
        "*   expands input into larger output,\n",
        "*   spreads value over larger area,\n",
        "*   kernel is moved over the output (via backprojection),\n",
        "*   computed by \"transposed discrete convolution\", as explained above.\n",
        "\n",
        "\n",
        "\n",
        "### How does it upsample feature maps?\n",
        "\n",
        "I introduce the notation:\n",
        "\n",
        "*For clarity, we assume that the input, filter, and output matrices are square. However, the transposed convolution works in full generality for arbitrary (rectangular) shapes.*\n",
        "\n",
        "*   $A=(a_{i,j})_{i,j=1,\\dots,n}$ - input (image $n\\times n$)\n",
        "*   $F=(f_{k,l})_{k,l=1,\\dots,m}$ -  filter (matrix $m\\times m$)\n",
        "*   $s\\in\\mathbb{N}$- Stride\n",
        "*   $p\\in\\mathbb{N}$- Padding\n",
        "*   Output $B=(b_{v,w})$  is the matrix $r\\times r$,\n",
        "\n",
        "where $r=(n-1)\\cdot s+m-2p$.\n",
        "\n",
        "Output is created in the following way:\n",
        "\n",
        "At the beginning: $b_{v,w}=0$ for all $v,w\\in\\{1,\\dots,r\\}$.\n",
        "\n",
        "Then, for each element $a_{i,j}$ of matrix $A$:\n",
        "\n",
        "1.   Define its position in output matrix $B$:\n",
        "\n",
        "$$v_0:=(i-1)\\cdot s-p+1,\\quad w_0:=(j-1)\\cdot s-p+1$$\n",
        "\n",
        "where $v_0$, $w_0$ are coordinates of the **top-left** corner in $B$ where the kernel centered on $a_{i,j}$ will be added.\n",
        "\n",
        "2.   Update the output matrix matrix $B$ as follows:\n",
        "\n",
        "For $k=1,\\cdots,m; l=1,\\dots,m$, such that:\n",
        "$$ 1\\leq v_0+k-1\\leq r,\\quad 1\\leq w_0+l-1\\leq r$$\n",
        "update:\n",
        "$$b_{v_0+k-1,w_0+l-1}:=b_{v_0+k-1,w_0+l-1}+a_{i,j}\\cdot f_{k,l}$$\n",
        "\n",
        "This way, all values from the input are projected (\"spread\") over the output space, and overlapping contributions are summed.\n",
        "\n",
        "\n",
        "\n",
        "### What are **stride**, **padding**, and **kernel size**, and how do they influence the result in a transposed convolution?\n",
        "\n",
        "\n",
        "*   **Stride** is the fixed natural number $s\\in\\mathbb{N}$ that determines the spacing between the locations where the filter is applied in the output.\n",
        "*   **Padding** is the fixed natural number $p\\in\\mathbb{N}$ that shifts the result spatially and influences the final output size.\n",
        "*   **Kernel size** is the size of $F$ matrix.\n",
        "\n",
        "The ifluence of these parameters was explained above."
      ],
      "metadata": {
        "id": "j-eaO9HPxPJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Manual Diagram**\n"
      ],
      "metadata": {
        "id": "lfbB3YnIExtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a hand-drawn example explaining how transposed convolution works.\n",
        "\n",
        "I chose a simple case with:\n",
        "\n",
        "*   input matrix of size $2\\times 2$,\n",
        "*   kernel of size $3\\times 3$,\n",
        "*   stride$=2$,\n",
        "*   padding$=1$,\n",
        "\n",
        "to clearly illustrate how each of these parameters affects the shape and values of the output.\n",
        "\n",
        "Each individual step shows:\n",
        "\n",
        "*   the contribution of a single input element,\n",
        "*   Ehow the kernel is scaled and positioned,\n",
        "*   and how overlapping values in the output are summed.\n",
        "\n"
      ],
      "metadata": {
        "id": "ePHA02NRNwPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Transposed convolution](https://raw.githubusercontent.com/MichalBalcerak/ML24-25/refs/heads/main/Transposed_convolution.jpg)"
      ],
      "metadata": {
        "id": "8rT3qpW-M9N-"
      }
    }
  ]
}